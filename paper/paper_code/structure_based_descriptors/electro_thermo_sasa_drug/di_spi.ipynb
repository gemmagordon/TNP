{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse propka files to get other structure metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folded and unfolded pI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import json\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "import freesasa\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'vhh_tsd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#propka_path = '/'+dataset_name+'_propka/'\n",
    "propka_path = '/propka/'+dataset_name+'_propka/'\n",
    "propka_files = [propka_path + f for f in os.listdir(propka_path) if f.endswith('.pka')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pi(file):\n",
    "    try:\n",
    "        with open(file) as rf:\n",
    "            pI_line = [line for line in rf.readlines() if line.startswith('The pI is')][0]\n",
    "            #print(pI_line.split()[3], pI_line.split()[6])\n",
    "            return pI_line.split()[3], pI_line.split()[6]\n",
    "    except Exception:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = dict()\n",
    "for f in propka_files:\n",
    "    structure = f.split('/')[-1].split('.')[0]\n",
    "    results = run_pi(f)\n",
    "    all_results[structure] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_results).T.reset_index()\n",
    "df.columns = ['SeqID','folded_pI', 'unfolded_pI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_fold_unfold_pi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free energy of folding, folded charge at ph7, unfolded charge at ph7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'vhh_tsd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# propka files\n",
    "#propka_path = '/'+dataset_name+'_propka/'\n",
    "propka_path = '/propka/'+dataset_name+'_propka/'\n",
    "propka_files = sorted([propka_path + f for f in os.listdir(propka_path) if f.endswith('.pka')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propka_data(f):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        with open(f) as rf:\n",
    "            all_lines = [l.strip() for l in rf.readlines()] \n",
    "\n",
    "        #sp = [n for n, l in enumerate(all_lines) if l.startswith('SUMMARY OF THIS PREDICTION')]\n",
    "        ffe = [n for n, l in enumerate(all_lines) if l.startswith('Free energy of')]\n",
    "        pc = [n for n, l in enumerate(all_lines) if l.startswith('Protein charge of folded')]\n",
    "\n",
    "        folding_free_energy = [i for i in all_lines[ffe[0]+1:pc[0]] if i and i[0].isnumeric()] # read all the lines between this section and where protein charge section starts\n",
    "        ffe_ph7 = [f for f in folding_free_energy if f.startswith('7.00')][0].split()[1] # extract just value for ph7\n",
    "\n",
    "        protein_charge = [i for i in all_lines[pc[0]+2:-1]]\n",
    "        ph, pc_ph7_unfolded, pc_ph7_folded  = [p for p in protein_charge if p.startswith('7.00')][0].split()\n",
    "\n",
    "    except Exception:\n",
    "        print('PROPKA:', f.split('/')[-1][:-4]) \n",
    "        \n",
    "    return {'SeqID': f.split('/')[-1][:-4], \n",
    "            'Free energy of folding':ffe_ph7,\n",
    "            'Unfolded charge pH7':pc_ph7_unfolded,\n",
    "            'Folded charge pH7': pc_ph7_folded}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_propka_results = []\n",
    "for p in propka_files:\n",
    "    results = propka_data(p)\n",
    "    all_propka_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_propka_results)#.T.reset_index()\n",
    "#df.columns = ['SeqID','folded_pI', 'unfolded_pI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_fold_unfold_charge.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SASA, SAP (structural aggregation propensity), DI (developability index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'vhh_tsd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_path = '/reduced_strucs/reduced_'+dataset_name+'/'\n",
    "structures = os.listdir(structure_path)\n",
    "structure_files = sorted([structure_path + structure for structure in structures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exposed_sasas():\n",
    "    \n",
    "    backbone = ['C', 'N', 'CA', 'O']\n",
    "    \n",
    "    exposed_sasas = defaultdict(dict)\n",
    "    \n",
    "    tripeptides = ['A_A_A.pdb', 'A_C_A.pdb', 'A_D_A.pdb', 'A_E_A.pdb', \n",
    "                'A_F_A.pdb', 'A_G_A.pdb', 'A_H_A.pdb', 'A_I_A.pdb',\n",
    "                'A_K_A.pdb', 'A_L_A.pdb', 'A_M_A.pdb', 'A_N_A.pdb',\n",
    "                'A_P_A.pdb', 'A_Q_A.pdb', 'A_R_A.pdb', 'A_S_A.pdb',\n",
    "                'A_T_A.pdb', 'A_V_A.pdb', 'A_W_A.pdb', 'A_Y_A.pdb']\n",
    "    \n",
    "    for peptide in tripeptides:\n",
    "        structure = freesasa.Structure(peptide)\n",
    "        sasa = freesasa.calc(structure)\n",
    "        \n",
    "        for atom in range(structure.nAtoms()):\n",
    "            if structure.residueNumber(atom).strip() == '3':\n",
    "                data = structure.residueName(atom).strip(), structure.atomName(atom).strip(), sasa.atomArea(atom)\n",
    "                exposed_sasas[data[0]].update({data[1]: data[2]})\n",
    "                \n",
    "    exposed_side_chain_sasas = {k: 0 for k in exposed_sasas.keys()}\n",
    "    \n",
    "    for aa in exposed_sasas:\n",
    "        for atom in exposed_sasas[aa].keys():\n",
    "            if not atom in backbone:\n",
    "                exposed_side_chain_sasas[aa] += exposed_sasas[aa][atom]\n",
    "\n",
    "    return exposed_side_chain_sasas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposed_side_chain_sasas = exposed_sasas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black, S. D., & Mould, D. R. (1991). Development of hydrophobicity parameters to analyze proteins which bear post- or cotranslational modifications. Analytical Biochemistry, 193(1), 72â€“82. doi:10.1016/0003-2697(91)90045-u \n",
    "hydrophobicity = {'ALA': 0.616,\n",
    "                'CYS': 0.680,\n",
    "                'ASP': 0.028,\n",
    "                'GLU': 0.043,\n",
    "                'PHE': 1.000,\n",
    "                'GLY': 0.501,\n",
    "                'HIS': 0.165,\n",
    "                'ILE': 0.943,\n",
    "                'LYS': 0.283,\n",
    "                'LEU': 0.943,\n",
    "                'MET': 0.738,\n",
    "                'ASN': 0.236,\n",
    "                'PRO': 0.711,\n",
    "                'GLN': 0.251,\n",
    "                'ARG': 0.000,\n",
    "                'SER': 0.359,\n",
    "                'THR': 0.450,\n",
    "                'VAL': 0.825,\n",
    "                'TRP': 0.878,\n",
    "                'TYR': 0.880}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sap(filename, exposed_side_chain_sasas = exposed_side_chain_sasas, hydrophobicity = hydrophobicity):\n",
    "    \n",
    "    def sasa(filename):\n",
    "\n",
    "        backbone = ['C', 'N', 'CA', 'O']\n",
    "\n",
    "        sasas = defaultdict(dict)\n",
    "        sasa_int = 0\n",
    "\n",
    "        structure = freesasa.Structure(filename)\n",
    "        sasa = freesasa.calc(structure)\n",
    "\n",
    "        for atom in range(structure.nAtoms()):\n",
    "            data = structure.residueName(atom).strip(), structure.residueNumber(atom).strip(), structure.chainLabel(atom).strip(), structure.atomName(atom).strip(), sasa.atomArea(atom)\n",
    "            idx = '_'.join(data[:3])\n",
    "            sasas[idx].update({data[3]: data[4]})\n",
    "            sasa_int += data[4]\n",
    "\n",
    "        return sasas, sasa_int\n",
    "    \n",
    "    def side_chain_sasa(sasas):\n",
    "\n",
    "        backbone = ['C', 'N', 'CA', 'O']\n",
    "\n",
    "        side_chain_sasas = {k: 0 for k in sasas.keys()}\n",
    "        side_chain_sasa_int = 0\n",
    "\n",
    "        for res in sasas:\n",
    "            for atom in sasas[res].keys():\n",
    "                if not atom in backbone:\n",
    "                    side_chain_sasas[res] += sasas[res][atom]\n",
    "                    side_chain_sasa_int += sasas[res][atom]\n",
    "\n",
    "        return side_chain_sasas, side_chain_sasa_int\n",
    "\n",
    "    try:\n",
    "    \n",
    "        sasas = sasa(filename)\n",
    "        side_chain_sasas_ = side_chain_sasa(sasas[0])\n",
    "        side_chain_sasas = side_chain_sasas_[0]\n",
    "\n",
    "        sap_values = {}\n",
    "\n",
    "        for i in side_chain_sasas:\n",
    "            for j in exposed_side_chain_sasas:\n",
    "                if i.startswith(j):\n",
    "                    try:\n",
    "                        #print(i, j, side_chain_sasas[i] / exposed_side_chain_sasas[j])\n",
    "                        sasa = side_chain_sasas[i] / exposed_side_chain_sasas[j]\n",
    "                    except ZeroDivisionError:\n",
    "                        if i.startswith('GLY'):\n",
    "                            #print(i, j, 0)\n",
    "                            sasa = 0 \n",
    "                    sap = sasa * hydrophobicity[j]\n",
    "                    sap_values[i] = sap\n",
    "\n",
    "        sap_score = sum(sap_values.values())\n",
    "        \n",
    "        return {'SeqID':filename.split('/')[-1][:-4], \n",
    "                'SASA': sasas[1], \n",
    "                'Side chain SASA':side_chain_sasas_[1],  \n",
    "                'SAP score':sap_score} # NOTE GG removed sap_values in output \n",
    "        \n",
    "    except Exception:\n",
    "        print(filename.split('/')[-1][:-4])\n",
    "        # print('SASA:', filename.split('/')[-1][:-4])\n",
    "        # sap_values = {'SER_2_L': np.inf, 'VAL_3_L': np.inf, 'LEU_4_L': np.inf}\n",
    "        \n",
    "        #return filename.split('/')[-1][:-4], np.inf, np.inf, sap_values, np.inf\n",
    "        return filename.split('/')[-1][:-4], np.inf, np.inf, np.inf     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sap_results = []\n",
    "for s in structure_files:\n",
    "    #structure = s.split('/')[-1].split('.')[0]\n",
    "    results = sap(s)\n",
    "    all_sap_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_sap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_sasa_sap.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DI (developability index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sciencedirect.com/science/article/pii/S0022354915317780"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'net charge' taken to mean folded charge of the structure at ph7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation for DI = SAP score - B x (net charge)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'vhh_tsd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_di(charge_data, sap_data):\n",
    "    \n",
    "    # load in charge data\n",
    "    charges = pd.read_csv(charge_data)\n",
    "    # load in sap data\n",
    "    saps = pd.read_csv(sap_data)\n",
    "    # merge data on SeqID so using correct corresponding charge and SAP values\n",
    "    df = charges.merge(saps, on='SeqID')\n",
    "\n",
    "    beta = 0.0815 # according to Greiff code base\n",
    "\n",
    "    di_values = []\n",
    "    for charge,sap in zip(list(df['SAP score']),list(df['Folded charge pH7'])):\n",
    "        di = sap - (beta * (charge)**2)\n",
    "        di_values.append(di)\n",
    "    \n",
    "    df['DI score'] = di_values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_data = '/folded_unfolded_charge/'+dataset_name+'_fold_unfold_charge.csv'\n",
    "sap_data = '/sasa_sap/'+dataset_name+'_sasa_sap.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_di(charge_data, sap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_di.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
